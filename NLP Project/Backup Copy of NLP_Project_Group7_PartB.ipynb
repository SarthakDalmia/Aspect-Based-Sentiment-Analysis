{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Backup Copy of NLP_Project_Group7_PartB.ipynb","provenance":[],"collapsed_sections":["Od4uB_ORsqQF","77Xb5KS5FFEp","oFBWz70ewcwU"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Od4uB_ORsqQF"},"source":["# Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nx7hlvFp0vGL","executionInfo":{"status":"ok","timestamp":1638783465499,"user_tz":-330,"elapsed":29232,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"95638e71-d280-4e90-d413-2fc4245ab0d8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7PcgfvLSCPT","executionInfo":{"status":"ok","timestamp":1638783655000,"user_tz":-330,"elapsed":189505,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"5d20c312-3f00-4302-9724-c96dbd7a6133"},"source":["!pip install torch==1.4.0\n","import torch\n","print(torch.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.2 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n","1.4.0\n"]}]},{"cell_type":"code","metadata":{"id":"MRYTkvaA8Os3","executionInfo":{"status":"ok","timestamp":1638783655001,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning) "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYoRocQhGeAp","executionInfo":{"status":"ok","timestamp":1638783737015,"user_tz":-330,"elapsed":82018,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"57606d20-690b-4aac-910e-f9dca35d88f6"},"source":["!pip install stanfordnlp\n","import stanfordnlp\n","stanfordnlp.download('en')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stanfordnlp\n","  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n","\u001b[?25l\r\u001b[K     |██                              | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 158 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (1.19.5)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (1.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (4.62.3)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanfordnlp) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (2.10)\n","Installing collected packages: stanfordnlp\n","Successfully installed stanfordnlp-0.2.0\n","Using the default treebank \"en_ewt\" for language \"en\".\n","Would you like to download the models for: en_ewt now? (Y/n)\n","y\n","\n","Default download directory: /root/stanfordnlp_resources\n","Hit enter to continue or type an alternate directory.\n","\n","\n","Downloading models for: en_ewt\n","Download location: /root/stanfordnlp_resources/en_ewt_models.zip\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 235M/235M [00:40<00:00, 5.77MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Download complete.  Models saved to: /root/stanfordnlp_resources/en_ewt_models.zip\n","Extracting models file for: en_ewt\n","Cleaning up...Done.\n"]}]},{"cell_type":"code","metadata":{"id":"04-sKY__1t58","executionInfo":{"status":"ok","timestamp":1638783738698,"user_tz":-330,"elapsed":1686,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["from xml.etree import cElementTree as ET\n","import pandas as pd\n","import string\n","import spacy\n","import re\n","import random\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import csv\n","import numpy as np\n","from collections import defaultdict"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gsszVN_1NAJ","executionInfo":{"status":"ok","timestamp":1638783800291,"user_tz":-330,"elapsed":412,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["root_dir = \"/content/drive/MyDrive/NLP Project/Topic 5/\"\n","train_folder = \"Train/SemEval'14-ABSA-TrainData_v2 & AnnotationGuidelines/\"\n","laptop_train_file = \"Laptop_Train_v2.xml\"\n","restaurants_train_file = \"Restaurants_Train_v2.xml\"\n","test_1_folder = \"Test1/ABSA_TestData_PhaseA/ABSA_TestData_PhaseA/\"\n","laptop_test_1_file = \"Laptops_Test_Data_PhaseA.xml\"\n","restaurants_test_1_file = \"Restaurants_Test_Data_PhaseA.xml\"\n","test_2_folder = \"Test2/ABSA_TestData_PhaseB/\"\n","laptop_test_2_file = \"Laptops_Test_Data_phaseB.xml\"\n","restaurants_test_2_file = \"Restaurants_Test_Data_phaseB.xml\""],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Y6IZZl-QpY3"},"source":["# Data Extraction & Cleaning"]},{"cell_type":"code","metadata":{"id":"O8tKAkEGTDgE","executionInfo":{"status":"ok","timestamp":1638783738699,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["class AspectWord():\n","    def __init__(self, aspect_term, sentiment_terms, polarity = None):\n","        # Words\n","        self.aspect_term = aspect_term\n","        # List of Words\n","        self.sentiment_terms = sentiment_terms\n","        # Polarity: +,-,neutral\n","        self.polarity = polarity\n","\n","    def __str__(self):\n","        return f\"Aspect Term: {self.aspect_term} Sentiment Terms: {self.sentiment_terms} Polarity: {self.polarity}\"\n","    \n","    def __repr__(self):\n","        return self.__str__()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEoYTdWZ9Gpr","executionInfo":{"status":"ok","timestamp":1638783738699,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["class Sentence():\n","    def __init__(self, sentence_id, sentence, data_type = \"Train\",\n","                 actual_sentence_id = None, actual_aspect_words = []): \n","        # Int\n","        self.sentence_id = sentence_id\n","        # String\n","        self.sentence = sentence\n","        # String\n","        self.data_type = data_type\n","        # String\n","        self.actual_sentence_id = actual_sentence_id\n","        # List of AspectWord\n","        self.actual_aspect_words = actual_aspect_words\n","        # List of AspectWord\n","        self.generated_aspect_words = []\n","\n","    def __str__(self):\n","        if self.data_type == \"Train\":\n","            return f\"ID: {self.sentence_id} Sentence: {self.sentence} {self.actual_aspect_words}\"\n","        else:\n","            return f\"ID: {self.sentence_id} Sentence: {self.sentence} {self.generated_aspect_words}\"\n","    \n","    def __repr__(self):\n","        return self.__str__()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIb2pocS9AiG","executionInfo":{"status":"ok","timestamp":1638783738700,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def xml_to_sentences(path,data_type = \"Train\"):\n","    data = []\n","    tree = ET.parse(path)\n","    root = tree.getroot()\n","    id = 1\n","    for page in root.findall('sentence'):\n","        sentence_id = id\n","        sentence = page[0].text\n","        actual_sentence_id = page.attrib[\"id\"]\n","        temp = []\n","        for i in range(1,len(page)):\n","            temp.append([x.attrib for x in page[i]])\n","        actual_aspect_terms = []\n","        actual_polarity = []\n","        if (data_type == \"Train\"):\n","            if len(temp) > 0:\n","            # Ignore Sentences without aspect terms if training data\n","                aspect_words = []\n","                for x in temp[0]:\n","                    aspect_words.append(AspectWord(x['term'],[],x['polarity']))\n","                id += 1\n","                data.append(Sentence(sentence_id, sentence, data_type, actual_sentence_id, aspect_words))\n","        elif (data_type == \"Test\"):\n","            data.append(Sentence(sentence_id, sentence, data_type, actual_sentence_id))\n","            id += 1\n","        else:\n","            print(\"Incorrect Data Type\")\n","            return None\n","    return data"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3gJ47H_EAw-","executionInfo":{"status":"ok","timestamp":1638783738701,"user_tz":-330,"elapsed":12,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def data_list_to_df(data_list, aspect_terms = \"actual\", aspect_polarity = True):\n","    \n","    data = pd.DataFrame(columns = [\"ID\",\"Sentence\",\"Actual Aspect Terms\",\"Actual Sentiment Terms\",\"Actual Polarities\",\"Generated Aspect Terms\",\"Generated Sentiment Terms\",\"Generated Polarities\"])\n","    \n","    for i in range(len(data_list)):\n","        data.loc[len(data.index)] = [data_list[i].sentence_id, data_list[i].sentence, [x.aspect_term for x in data_list[i].actual_aspect_words], [x.sentiment_terms for x in data_list[i].actual_aspect_words], [x.polarity for x in data_list[i].actual_aspect_words], [x.aspect_term for x in data_list[i].generated_aspect_words], [x.sentiment_terms for x in data_list[i].generated_aspect_words], [x.polarity for x in data_list[i].generated_aspect_words]] \n","    \n","    if aspect_terms == \"actual\":\n","        data.drop([\"Generated Aspect Terms\",\"Generated Sentiment Terms\",\"Generated Polarities\",\"Actual Sentiment Terms\"], axis = 1, inplace = True)\n","    elif aspect_terms == \"generated\":\n","        data.drop([\"Actual Aspect Terms\",\"Actual Sentiment Terms\",\"Actual Polarities\"], axis = 1, inplace = True)\n","    elif aspect_terms == \"none\":\n","        data.drop([\"Generated Aspect Terms\",\"Generated Sentiment Terms\",\"Generated Polarities\",\"Actual Aspect Terms\",\"Actual Sentiment Terms\",\"Actual Polarities\"], axis = 1, inplace = True)\n","\n","    if not aspect_polarity:\n","        try:\n","            data.drop([\"Generated Polarities\"],axis=1, inplace = True)\n","        except:\n","            pass\n","        try:\n","            data.drop([\"Actual Polarities\"],axis=1, inplace = True)\n","        except:\n","            pass\n","\n","    return data"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"R_bW8EQv1o_d","executionInfo":{"status":"ok","timestamp":1638786602038,"user_tz":-330,"elapsed":8886,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"6545c4bb-45e2-4c05-c2e7-b6318a66c92a"},"source":["laptop_train_data = xml_to_sentences(root_dir + train_folder + laptop_train_file)\n","laptop_train_data_size = len(laptop_train_data)\n","print(f\"Total sentences: {laptop_train_data_size}\")\n","laptop_train_data_df = data_list_to_df(laptop_train_data, aspect_terms = \"actual\", aspect_polarity = True)\n","laptop_train_data_df.head()"],"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Total sentences: 1488\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Actual Aspect Terms</th>\n","      <th>Actual Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>I charge it at night and skip taking the cord ...</td>\n","      <td>[cord, battery life]</td>\n","      <td>[neutral, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>The tech guy then said the service center does...</td>\n","      <td>[service center, \"sales\" team, tech guy]</td>\n","      <td>[negative, negative, neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>it is of high quality, has a killer GUI, is ex...</td>\n","      <td>[quality, GUI, applications, use]</td>\n","      <td>[positive, positive, positive, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Easy to start up and does not overheat as much...</td>\n","      <td>[start up]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>I even got my teenage son one, because of the ...</td>\n","      <td>[features, iChat, Photobooth, garage band]</td>\n","      <td>[positive, positive, positive, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...                         Actual Polarities\n","0  1  ...                       [neutral, positive]\n","1  2  ...             [negative, negative, neutral]\n","2  3  ...  [positive, positive, positive, positive]\n","3  4  ...                                [positive]\n","4  5  ...  [positive, positive, positive, positive]\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"OvksVdL85A9I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638786602039,"user_tz":-330,"elapsed":12,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"fe938e74-9bb1-4c36-d25c-936bce016374"},"source":["# Split into train and validation\n","np.random.seed(7)\n","random.seed(9)\n","laptop_train_data, laptop_valid_data = sklearn.model_selection.train_test_split(laptop_train_data, test_size=0.1)\n","print(f\"Size of Training Data:{len(laptop_valid_data)}, Size of Validation Data: {len(laptop_train_data)}\")"],"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of Training Data:149, Size of Validation Data: 1339\n"]}]},{"cell_type":"markdown","metadata":{"id":"77Xb5KS5FFEp"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"yzboBF5Ls_CL","executionInfo":{"status":"ok","timestamp":1638786602039,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# Remove Punctuations - {, . \"\" ' ;}\n","# Check stopword Removal"],"execution_count":90,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9yUW3JYsyg0"},"source":["# Find Aspect Terms"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mv7_H0EAQxOC","executionInfo":{"status":"ok","timestamp":1638786604119,"user_tz":-330,"elapsed":2088,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"cad94e58-16d7-43c3-a101-741451d525da"},"source":["nlp = stanfordnlp.Pipeline()"],"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Use device: cpu\n","---\n","Loading: tokenize\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","---\n","Loading: pos\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","---\n","Loading: lemma\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","Building an attentional Seq2Seq model...\n","Using a Bi-LSTM encoder\n","Using soft attention for LSTM.\n","Finetune all embeddings.\n","[Running seq2seq lemmatizer with edit classifier]\n","---\n","Loading: depparse\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","Done loading processors!\n","---\n"]}]},{"cell_type":"code","metadata":{"id":"aaNQFY8cqUm1","executionInfo":{"status":"ok","timestamp":1638786604120,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def extract_attributes(text):\n","    doc = nlp(text)\n","    parsed_text = {'word':[], 'lemma':[], 'pos':[], 'dep':[], 'gov':[], 'gov_pos':[]}\n","    for sent in doc.sentences:\n","        for wrd in sent.words:\n","            parsed_text['word'].append(wrd.text)\n","            parsed_text['lemma'].append(wrd.lemma)\n","            parsed_text['pos'].append(wrd.pos)\n","            parsed_text['dep'].append(wrd.dependency_relation)\n","    for sent in doc.sentences:\n","        for wrd in sent.words:        \n","            if wrd.governor == 0:\n","                parsed_text['gov'].append(\"ROOT\")\n","                parsed_text['gov_pos'].append(\"-\")\n","            else:   \n","                parsed_text['gov'].append(parsed_text['word'][wrd.governor-1])\n","                parsed_text['gov_pos'].append(parsed_text['pos'][wrd.governor-1])\n","    \n","    return pd.DataFrame(parsed_text)"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"bu7SkTslyip8","executionInfo":{"status":"ok","timestamp":1638786604121,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"4f7c1cd0-35e3-48da-e95f-fedf1dcfb2c9"},"source":["text = \"This is not a good laptop.\"\n","extract_attributes(text)"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>lemma</th>\n","      <th>pos</th>\n","      <th>dep</th>\n","      <th>gov</th>\n","      <th>gov_pos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This</td>\n","      <td>this</td>\n","      <td>DT</td>\n","      <td>nsubj</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>is</td>\n","      <td>be</td>\n","      <td>VBZ</td>\n","      <td>cop</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>not</td>\n","      <td>not</td>\n","      <td>RB</td>\n","      <td>advmod</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>DT</td>\n","      <td>det</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>good</td>\n","      <td>good</td>\n","      <td>JJ</td>\n","      <td>amod</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>laptop</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","      <td>root</td>\n","      <td>ROOT</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>punct</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     word   lemma  pos     dep     gov gov_pos\n","0    This    this   DT   nsubj  laptop      NN\n","1      is      be  VBZ     cop  laptop      NN\n","2     not     not   RB  advmod  laptop      NN\n","3       a       a   DT     det  laptop      NN\n","4    good    good   JJ    amod  laptop      NN\n","5  laptop  laptop   NN    root    ROOT       -\n","6       .       .    .   punct  laptop      NN"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"18WVBe7Q82gd","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1638786604861,"user_tz":-330,"elapsed":752,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"6bafc2c0-bfa1-49c2-e60b-9c5b2d0916bb"},"source":["text = \"This laptop is not good.\"\n","extract_attributes(text)"],"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>lemma</th>\n","      <th>pos</th>\n","      <th>dep</th>\n","      <th>gov</th>\n","      <th>gov_pos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This</td>\n","      <td>this</td>\n","      <td>DT</td>\n","      <td>det</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>laptop</td>\n","      <td>laptop</td>\n","      <td>NN</td>\n","      <td>nsubj</td>\n","      <td>good</td>\n","      <td>JJ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>is</td>\n","      <td>be</td>\n","      <td>VBZ</td>\n","      <td>cop</td>\n","      <td>good</td>\n","      <td>JJ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>not</td>\n","      <td>not</td>\n","      <td>RB</td>\n","      <td>advmod</td>\n","      <td>good</td>\n","      <td>JJ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>good</td>\n","      <td>good</td>\n","      <td>JJ</td>\n","      <td>root</td>\n","      <td>ROOT</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>punct</td>\n","      <td>good</td>\n","      <td>JJ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     word   lemma  pos     dep     gov gov_pos\n","0    This    this   DT     det  laptop      NN\n","1  laptop  laptop   NN   nsubj    good      JJ\n","2      is      be  VBZ     cop    good      JJ\n","3     not     not   RB  advmod    good      JJ\n","4    good    good   JJ    root    ROOT       -\n","5       .       .    .   punct    good      JJ"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","metadata":{"id":"0kC4ChZC9SMm","executionInfo":{"status":"ok","timestamp":1638786604866,"user_tz":-330,"elapsed":12,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def parse_compound_aspects(data):\n","    count = 0\n","    for i in range(len(data)):\n","        j = 0\n","        generated_aspect_words_to_be_deleted = set()\n","        while(j < len(data[i].generated_aspect_words)):\n","            generated_aspect_term = data[i].generated_aspect_words[j].aspect_term\n","            individual_aspect_terms = generated_aspect_term.split(\" \")\n","            if(len(individual_aspect_terms) > 1):\n","                for individual_aspect_term in individual_aspect_terms:\n","                    # print(f\"Generated: {data[i].generated_aspect_words}\")\n","                    k = 0\n","                    while(k < len(data[i].generated_aspect_words)):\n","                        if k == j:\n","                            k += 1\n","                            continue\n","                        # print(f\"i : {i} j : {j} k : {k} {individual_aspect_term}\")\n","                        if individual_aspect_term == data[i].generated_aspect_words[k].aspect_term:\n","                            data[i].generated_aspect_words[j].sentiment_terms += (data[i].generated_aspect_words[k].sentiment_terms)\n","                            generated_aspect_words_to_be_deleted.add(data[i].generated_aspect_words[k])\n","                            # print(f\"Compound: {generated_aspect_term}, Deleting {data[i].generated_aspect_words[k]}\")\n","                            count += 1\n","                        k += 1\n","            j += 1\n","        for generated_aspect_word_to_be_deleted in generated_aspect_words_to_be_deleted:\n","            data[i].generated_aspect_words.remove(generated_aspect_word_to_be_deleted)\n","    return count\n","\n","def add_or_update_aspect_word(sentence, aspect_term, sentiment_term):\n","    if sentiment_term == None:\n","        sentence.generated_aspect_words.append(AspectWord(aspect_term, []))\n","        return True\n","    for i in range(len(sentence.generated_aspect_words)):\n","        if sentence.generated_aspect_words[i].aspect_term == aspect_term:\n","            sentence.generated_aspect_words[i].sentiment_terms.append(sentiment_term)\n","            return True\n","\n","    sentence.generated_aspect_words.append(AspectWord(aspect_term, [sentiment_term]))\n","    return True\n","\n","def update_aspect_word(sentence, aspect_term, sentiment_term):\n","    for i in range(len(sentence.generated_aspect_words)):\n","        if sentence.generated_aspect_words[i].aspect_term == aspect_term:\n","            sentence.generated_aspect_words[i].sentiment_terms.append(sentiment_term)\n","            return True\n","    return False\n","\n","\n","def update_sentiment(sentence, sentiment_base, sentiment_modifier):\n","    for i in range(len(sentence.generated_aspect_words)):\n","        if sentiment_base in sentence.generated_aspect_words[i].sentiment_terms:\n","            sentence.generated_aspect_words[i].sentiment_terms.remove(sentiment_base)\n","            sentence.generated_aspect_words[i].sentiment_terms.append(sentiment_modifier+\" \"+sentiment_base)\n","            return True\n","    return False\n","\n","\n","def generate_aspect_words(data):\n","    dependencies= {\"nsubj\":[],\"amod\":[],\"dobj\":[],\"nmod\":[],\"acl\":[],\"conj\":[],\"compound\":[]}\n","\n","    for i in range(len(data)):\n","        \n","        adj_mods = []\n","        adj_mod_nn = []\n","        \n","        extracted_attributes_df = extract_attributes(data[i].sentence)\n","        data[i].generated_aspect_words.clear()\n","\n","        # Rules:\n","        for j in extracted_attributes_df.index:\n","            \n","            # Bell, based in Los Angeles, makes and distributes electronic, computer and building products.\n","            if extracted_attributes_df['dep'][j] == \"nsubj\":\n","                # Example: (best, display)\n","                if extracted_attributes_df['gov_pos'][j] in [\"JJ\", \"JJR\", \"JJS\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                # Example: (distributes, XYZ Company)\n","                elif extracted_attributes_df['gov_pos'][j] in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                # dependencies[\"nsubj\"].append(((extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j]),(extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j])))\n","            \n","            elif extracted_attributes_df['dep'][j] == \"amod\":\n","                # Example: (products, electronic)\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"JJ\", \"JJR\", \"JJS\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                # Example: (products, building)\n","                elif extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                # dependencies[\"amod\"].append(((extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j]),(extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j])))\n","            \n","            elif extracted_attributes_df['dep'][j] == \"obj\":\n","                # Example: (makes, products)\n","                if extracted_attributes_df['gov_pos'][j] in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                    # dependencies[\"dobj\"].append(((extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j]),(extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j])))\n","\n","            elif extracted_attributes_df['dep'][j] == \"nmod\":\n","                # Both are aspects\n","                # Example: (display, computer)\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NS\"]:\n","                    # Check which before\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j], None)\n","                    # dependencies[\"nmod\"].append(((extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j],extracted_attributes_df['pos'][j])))\n","\n","                elif extracted_attributes_df['gov_pos'][j] in [\"JJ\"] and extracted_attributes_df['pos'][j] in [\"NN\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                    # dependencies[\"nmod\"].append(((extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j]),(extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j])))\n","\n","            elif extracted_attributes_df['dep'][j] == \"acl\":\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"JJ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                \n","                elif extracted_attributes_df['gov_pos'][j] in [\"NNS\"] and extracted_attributes_df['pos'][j] in [\"VBP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                # dependencies[\"acl\"].append(((extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j]),(extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j])))\n","\n","            elif extracted_attributes_df['dep'][j] == \"conj\":\n","                # Both are aspects\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    # Check which before\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j], None)\n","                    # dependencies[\"conj\"].append(((extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j],extracted_attributes_df['pos'][j])))\n","\n","                elif extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"JJ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                    # dependencies[\"conj\"].append(((extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j]),(extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j])))\n","\n","                elif extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"VBZ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                    # dependencies[\"conj\"].append(((extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j]),(extracted_attributes_df['word'][j],extracted_attributes_df['pos'][j])))\n","\n","            elif extracted_attributes_df['dep'][j] == \"compound\":\n","                # Both are aspects\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"NN\"]:\n","                    # Check which before\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j], None)\n","                    # dependencies[\"compound\"].append(((extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j],extracted_attributes_df['gov_pos'][j],extracted_attributes_df['pos'][j])))\n","\n","            # New Rules:::\n","            elif extracted_attributes_df['dep'][j] == \"advmod\":\n","                # Example: (not, laptop)\n","                # if extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"RB\"]:\n","                #     adj_mod_nn.append([extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j]])\n","\n","                # Example: (not, good)\n","                if extracted_attributes_df['gov_pos'][j] in [\"JJ\"] and extracted_attributes_df['pos'][j] in [\"RB\"]:\n","                    adj_mods.append([extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j]])\n","\n","        for mods in adj_mod_nn:\n","            update_aspect_word(data[i], mods[0], mods[1])\n","        \n","        for mods in adj_mods:\n","            update_sentiment(data[i], mods[0], mods[1])\n","\n","    parse_compound_aspects(data)\n","    return dependencies"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"id":"B54ACZ0ADxbJ","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638786862400,"user_tz":-330,"elapsed":257545,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"76cd0bd8-9b3c-4e0d-8930-883e2619a7e9"},"source":["train_dependencies = generate_aspect_words(laptop_train_data)\n","laptop_train_data_df = data_list_to_df(laptop_train_data, aspect_terms = \"generated\", aspect_polarity = True)\n","laptop_train_data_df.head()"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>611</td>\n","      <td>Not only are the versions of these programs ab...</td>\n","      <td>[versions]</td>\n","      <td>[[worked, able, graphically superior]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>260</td>\n","      <td>Sometimes you really have to tap the pad to ge...</td>\n","      <td>[pad]</td>\n","      <td>[[tap]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>799</td>\n","      <td>-When battery life went to 4 hours or less, to...</td>\n","      <td>[battery life]</td>\n","      <td>[[went]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>397</td>\n","      <td>If you don't feel comfortable doing it yoursel...</td>\n","      <td>[case, one, Buy]</td>\n","      <td>[[buy], [white, bought], [Best]]</td>\n","      <td>[None, None, None]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>834</td>\n","      <td>/ awesome cooling system/ much better grafics ...</td>\n","      <td>[cooling system, card, GB RAM, RAM screen, bac...</td>\n","      <td>[[awesome], [better], [], [LED], [LED], [LED, ...</td>\n","      <td>[None, None, None, None, None, None]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    ID  ...                  Generated Polarities\n","0  611  ...                                [None]\n","1  260  ...                                [None]\n","2  799  ...                                [None]\n","3  397  ...                    [None, None, None]\n","4  834  ...  [None, None, None, None, None, None]\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"VQnzE7xzeot_","executionInfo":{"status":"ok","timestamp":1638786862401,"user_tz":-330,"elapsed":32,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def match_aspect_terms(actual_aspect_term, generated_aspect_term):\n","    n = len(generated_aspect_term.split(\" \"))\n","    for i in range(n):\n","        temp = generated_aspect_term.split(\" \",maxsplit = i)\n","        if len(temp) > 1:\n","            rest = temp[1]\n","        else:\n","            rest = temp[0]\n","        if re.search(rest, actual_aspect_term):\n","            return len(rest)/len(actual_aspect_term)\n","        generated_aspect_term = rest\n","    return 0"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fR9eSBUA03s","executionInfo":{"status":"ok","timestamp":1638786862401,"user_tz":-330,"elapsed":31,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def aspect_term_performance(data):\n","    true_positives = 0\n","    false_positives = 0\n","    no_of_actual_aspect_terms = 0\n","    no_of_generated_aspect_terms = 0\n","\n","    for i in range(len(data)):\n","        no_of_generated_aspect_terms += len(data[i].generated_aspect_words)\n","        no_of_actual_aspect_terms += len(data[i].actual_aspect_words)\n","        for generated_aspect_word in data[i].generated_aspect_words:\n","            found = False\n","            for actual_aspect_word in data[i].actual_aspect_words:\n","                matched_part = match_aspect_terms(actual_aspect_word.aspect_term, generated_aspect_word.aspect_term)\n","                if matched_part > 0:\n","                    true_positives += matched_part\n","                    found = True\n","                    break\n","            if not found:\n","                false_positives += 1\n","\n","    ratios = {\"Aspect Term Extraction Precision\": true_positives / no_of_generated_aspect_terms, \"Aspect Term Extraction Recall\":true_positives/no_of_actual_aspect_terms, \"Aspect Term Extraction True Positives\":true_positives, \"Actual Aspect Terms\":no_of_actual_aspect_terms, \"Generated Aspect Terms\":no_of_generated_aspect_terms}\n","    return ratios"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"w49l-LwWGc23","executionInfo":{"status":"ok","timestamp":1638786862402,"user_tz":-330,"elapsed":31,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"318a418c-ba20-4b5d-fb1b-9188d7bf3c04"},"source":["laptop_train_data_ratios = aspect_term_performance(laptop_train_data)\n","pd.DataFrame.from_dict(laptop_train_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.419667</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.566810</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>1191.433998</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>2102.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>2839.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        Parameters\n","Aspect Term Extraction Precision          0.419667\n","Aspect Term Extraction Recall             0.566810\n","Aspect Term Extraction True Positives  1191.433998\n","Actual Aspect Terms                    2102.000000\n","Generated Aspect Terms                 2839.000000"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","metadata":{"id":"HXny_pPTtgsh"},"source":["# Train the Model\n","Make a frequency dictionary for all the Sentiment Words"]},{"cell_type":"code","metadata":{"id":"SFMs7p3YtU6j","executionInfo":{"status":"ok","timestamp":1638786862403,"user_tz":-330,"elapsed":31,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def train(data):\n","    # Do preprocessing if needed\n","    sentiment_terms_frequency = {}\n","    for sentence in data:\n","        for generated_aspect_word in sentence.generated_aspect_words:\n","            polarity = None\n","            for actual_aspect_word in sentence.actual_aspect_words:\n","                matched_part = match_aspect_terms(actual_aspect_word.aspect_term, generated_aspect_word.aspect_term)\n","                if matched_part > 0: \n","                    if actual_aspect_word.polarity == 'positive':\n","                        polarity = 1\n","                    \n","                    elif actual_aspect_word.polarity == 'negative':\n","                        polarity = -1\n","                    \n","                    else:\n","                        polarity = 0\n","                    break    \n","            if polarity ==  None:\n","                continue\n","            for sentiment_term in generated_aspect_word.sentiment_terms:\n","                if sentiment_term in list(sentiment_terms_frequency.keys()): \n","                    sentiment_terms_frequency[sentiment_term]['frequency'] += 1\n","                    sentiment_terms_frequency[sentiment_term]['polarity'] += (polarity)\n","                \n","                else:\n","                    sentiment_terms_frequency[sentiment_term] = {'frequency':1, 'polarity':polarity}\n","\n","    for key in list(sentiment_terms_frequency.keys()):\n","        sentiment_terms_frequency[key] = (sentiment_terms_frequency[key]['polarity']/sentiment_terms_frequency[key]['frequency'])\n","\n","    return sentiment_terms_frequency"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"f9CeSkQu9v9P","executionInfo":{"status":"ok","timestamp":1638786862403,"user_tz":-330,"elapsed":31,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"30d02e58-f07d-4919-a3ff-f9ba19c39898"},"source":["laptop_sentiment_terms_frequency_train = train(laptop_train_data)\n","print(f\"Number of Sentiment Terms: {len(laptop_sentiment_terms_frequency_train)}\")\n","df = pd.DataFrame.from_dict(laptop_sentiment_terms_frequency_train, orient = 'index', columns =[\"Polarity\"])\n","df.head()"],"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Sentiment Terms: 674\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tap</th>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>went</th>\n","      <td>-0.833333</td>\n","    </tr>\n","    <tr>\n","      <th>buy</th>\n","      <td>-0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>awesome</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>better</th>\n","      <td>0.142857</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Polarity\n","tap     -1.000000\n","went    -0.833333\n","buy     -0.333333\n","awesome  1.000000\n","better   0.142857"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","metadata":{"id":"pYWjESWJtw9y"},"source":["# Test the Model"]},{"cell_type":"code","metadata":{"id":"-0JS4mxS6UWl","executionInfo":{"status":"ok","timestamp":1638786862404,"user_tz":-330,"elapsed":26,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def predict(data, sentiment_terms_frequency):\n","    generate_aspect_words(data)\n","    unk_words = set() \n","    for i in range(len(data)):\n","        for j in range(len(data[i].generated_aspect_words)):\n","            sentiment_terms = data[i].generated_aspect_words[j].sentiment_terms\n","            unk = 0\n","            polarity = 0\n","            for term in sentiment_terms:\n","                if term not in sentiment_terms_frequency.keys():\n","                    unk += 1\n","                    unk_words.add(term)\n","                else:\n","                    polarity += sentiment_terms_frequency[term]\n","            if (len(sentiment_terms) - unk != 0):\n","                data[i].generated_aspect_words[j].polarity = polarity/(len(sentiment_terms)-unk)\n","            else:\n","                data[i].generated_aspect_words[j].polarity = 0\n","    return len(unk_words)\n","\n","def find_polarity(value, threshold = 0.1):\n","    if (value < -1*threshold):\n","        return \"negative\"\n","    elif (value > threshold):\n","        return \"positive\"\n","    else:\n","        return \"neutral\"\n","\n","def classify(data, sentiment_terms_frequency):\n","    no_of_unk_words = predict(data, sentiment_terms_frequency)\n","    for i in range(len(data)):\n","        for j in range(len(data[i].generated_aspect_words)):\n","            data[i].generated_aspect_words[j].polarity = find_polarity(data[i].generated_aspect_words[j].polarity)\n","    return no_of_unk_words"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ow5AwcMCNmN","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638786866540,"user_tz":-330,"elapsed":4162,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"c3def21e-bb2a-4479-e9fc-be53acd07eea"},"source":["laptop_test_1_data = xml_to_sentences(root_dir + test_1_folder + laptop_test_1_file, data_type = \"Test\")\n","laptop_test_1_data_df = data_list_to_df(laptop_test_1_data, aspect_terms = \"none\", aspect_polarity = False)\n","laptop_test_1_data_df.head()"],"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Boot time is super fast, around anywhere from ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>tech support would not fix the problem unless ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>but in resume this computer rocks!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Set up was easy.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID                                           Sentence\n","0  1  Boot time is super fast, around anywhere from ...\n","1  2  tech support would not fix the problem unless ...\n","2  3                 but in resume this computer rocks!\n","3  4                                   Set up was easy.\n","4  5  Did not enjoy the new Windows 8 and touchscree..."]},"metadata":{},"execution_count":103}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"ZzwFWk-WFZdY","executionInfo":{"status":"ok","timestamp":1638786998291,"user_tz":-330,"elapsed":131763,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"eade6403-127f-4790-aadb-22421470af27"},"source":["laptop_test_1_predictions_unk_count = classify(laptop_test_1_data, laptop_sentiment_terms_frequency_train)\n","print(\"Number of Unknown Sentiment Terms:\", laptop_test_1_predictions_unk_count)\n","laptop_test_1_data_df = data_list_to_df(laptop_test_1_data, aspect_terms = \"generated\", aspect_polarity = True)\n","laptop_test_1_data_df.head()"],"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Unknown Sentiment Terms: 317\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Boot time is super fast, around anywhere from ...</td>\n","      <td>[Boot time]</td>\n","      <td>[[super fast]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>tech support would not fix the problem unless ...</td>\n","      <td>[tech support, problem, plan]</td>\n","      <td>[[fix], [fix], [bought]]</td>\n","      <td>[negative, negative, negative]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>but in resume this computer rocks!</td>\n","      <td>[computer]</td>\n","      <td>[[rocks]]</td>\n","      <td>[neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Set up was easy.</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n","      <td>[functions, Windows]</td>\n","      <td>[[new, enjoy], [enjoy]]</td>\n","      <td>[neutral, neutral]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...            Generated Polarities\n","0  1  ...                      [positive]\n","1  2  ...  [negative, negative, negative]\n","2  3  ...                       [neutral]\n","3  4  ...                              []\n","4  5  ...              [neutral, neutral]\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":104}]},{"cell_type":"markdown","metadata":{"id":"4UhcH3uWuLym"},"source":["# Performance of Sentiment Classification"]},{"cell_type":"code","metadata":{"id":"Ys0Azbo3O_e-","executionInfo":{"status":"ok","timestamp":1638786998291,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# Split data and do this\n","def classification_performance(data):\n","    matches = 0\n","    non_matches = 0\n","    for i in range(len(data)):\n","        for actual_aspect_word in data[i].actual_aspect_words:\n","            actual_aspect_term = actual_aspect_word.aspect_term\n","            actual_polarity = actual_aspect_word.polarity\n","            for generated_aspect_word in data[i].generated_aspect_words:\n","                if (match_aspect_terms(actual_aspect_term, generated_aspect_word.aspect_term) > 0):\n","                    if (actual_polarity == generated_aspect_word.polarity):\n","                        matches+=1\n","                    else:\n","                        non_matches+=1\n","                    break\n","\n","    return {\"Sentiment Matches\":matches, \"Sentiment Non-Matches\":non_matches, \"Sentiment Classification Precision\":matches/(matches+non_matches)}"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSweiDRCqo-s","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1638787027304,"user_tz":-330,"elapsed":29017,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"194569c7-de22-41d7-ef2f-9ceddb1b945d"},"source":["laptop_valid_data_predictions_unk_count = classify(laptop_valid_data, laptop_sentiment_terms_frequency_train)\n","print(\"Unknown Sentiment Terms:\", laptop_valid_data_predictions_unk_count)\n","laptop_valid_data_df = data_list_to_df(laptop_valid_data, aspect_terms = \"none\", aspect_polarity = False)\n","laptop_valid_data_df.head()"],"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["Unknown Sentiment Terms: 105\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>433</td>\n","      <td>WHEN TYPING, LETTERS AND SPACES ARE FREQUENTLY...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>59</td>\n","      <td>I love the glass touchpad.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1021</td>\n","      <td>Later it held zero charge and its replacemen...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>678</td>\n","      <td>This computer is exceptionally thin for it's s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1319</td>\n","      <td>It has just enough RAM to run smoothly and eno...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     ID                                           Sentence\n","0   433  WHEN TYPING, LETTERS AND SPACES ARE FREQUENTLY...\n","1    59                         I love the glass touchpad.\n","2  1021    Later it held zero charge and its replacemen...\n","3   678  This computer is exceptionally thin for it's s...\n","4  1319  It has just enough RAM to run smoothly and eno..."]},"metadata":{},"execution_count":106}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"ttq7OdZduUp7","executionInfo":{"status":"ok","timestamp":1638787027304,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}},"outputId":"2bddccf4-98f2-4bbc-e0ff-38d41c3986eb"},"source":["laptop_valid_data_ratios = aspect_term_performance(laptop_valid_data)\n","laptop_valid_data_ratios.update(classification_performance(laptop_valid_data))\n","pd.DataFrame.from_dict(laptop_valid_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.467085</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.607576</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>155.539348</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>256.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>333.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Matches</th>\n","      <td>83.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Non-Matches</th>\n","      <td>86.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Classification Precision</th>\n","      <td>0.491124</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       Parameters\n","Aspect Term Extraction Precision         0.467085\n","Aspect Term Extraction Recall            0.607576\n","Aspect Term Extraction True Positives  155.539348\n","Actual Aspect Terms                    256.000000\n","Generated Aspect Terms                 333.000000\n","Sentiment Matches                       83.000000\n","Sentiment Non-Matches                   86.000000\n","Sentiment Classification Precision       0.491124"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"ZoT75a8kI7OR","executionInfo":{"status":"ok","timestamp":1638787027305,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["def write_to_csv(data, path):\n","    data_df = data_list_to_df(data, aspect_terms = \"both\", aspect_polarity = True)\n","    data_df.to_csv(path_or_buf = path)"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"yO3IO42iNgmC","executionInfo":{"status":"ok","timestamp":1638787027305,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# write_to_csv(laptop_train_data, root_dir + train_folder + \"generated_laptop_train_data.csv\")\n","# write_to_csv(laptop_test_1_data, root_dir + train_folder + \"generated_laptop_test_1_data.csv\")\n","# write_to_csv(laptop_valid_data, root_dir + train_folder + \"generated_laptop_valid_data.csv\")"],"execution_count":109,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFBWz70ewcwU"},"source":["# Demo\n"]},{"cell_type":"code","metadata":{"id":"1FnNM0E8whFL","executionInfo":{"status":"ok","timestamp":1638787027307,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# def test(string):\n","#   columns = ['text','aspect_terms','aspect_categories']\n","#   dft = pd.DataFrame(columns=columns)\n","#   temp = [string,None,None]\n","#   dft.loc[len(dft)] = temp\n","#   laptop_test_data = dft\n","#   laptop_test_predictions, laptop_test_predictions_unk_count = predict(laptop_test_data, laptop_sentiment_words_frequency_train)\n","#   print(laptop_test_predictions.head())\n","#   classify(laptop_test_predictions)\n","#   print(\"Unknown Sentiment Words:\", laptop_test_predictions_unk_count)\n","#   print(\"\")\n","#   print(\"Analysis:\")\n","#   print(laptop_test_predictions)"],"execution_count":110,"outputs":[]},{"cell_type":"code","metadata":{"id":"30NZ1wCl_cdi","executionInfo":{"status":"ok","timestamp":1638787027308,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# test(\"It is a good laptop but bad mouse\")\n"],"execution_count":111,"outputs":[]},{"cell_type":"code","metadata":{"id":"BoOTyO3KW8ZM","executionInfo":{"status":"ok","timestamp":1638787027308,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# test(\"It is super fast and has outstanding graphics.\")"],"execution_count":112,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaSOI7MZW8F7","executionInfo":{"status":"ok","timestamp":1638787027309,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"}}},"source":["# test(\"Laptop good, mouse bad\")"],"execution_count":113,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3JHhV1SFXvoj"},"source":["## Shortcomings and improvements\n","\n","* Compound aspect terms\n","* Compount sentiment words\n","* More rules, curent ones don't handle many cases \n","* Improve accuracy\n","* Precision of genration of aspect terms is an approximation\n","* Can try Ngram model - for 3 cases with aspect-aspect\n","\n"]}]}