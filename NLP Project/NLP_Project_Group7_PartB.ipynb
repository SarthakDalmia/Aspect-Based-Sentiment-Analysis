{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Project_Group7_PartB.ipynb","provenance":[],"collapsed_sections":["Z9yUW3JYsyg0","J1b0dEF69dbm","HXny_pPTtgsh","pYWjESWJtw9y"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Od4uB_ORsqQF"},"source":["# Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nx7hlvFp0vGL","executionInfo":{"elapsed":106774,"status":"ok","timestamp":1638884182634,"user":{"displayName":"Shubh Pragnesh Shah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07581433821988336228"},"user_tz":-330},"outputId":"e64b45e6-9eb7-408d-d177-2bdd7c6a3738"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"O7PcgfvLSCPT","outputId":"56dd7907-63a8-428a-dc16-bccc56241c6c"},"source":["!pip install torch==1.4.0\n","import torch\n","print(torch.__version__)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.1 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n","1.4.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"MRYTkvaA8Os3"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"GYoRocQhGeAp","outputId":"43130c37-fd7f-47f9-f498-ca665f06c1c0"},"source":["!pip install stanfordnlp\n","import stanfordnlp\n","stanfordnlp.download('en')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting stanfordnlp\n","  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n","\u001b[?25l\r\u001b[K     |██                              | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 158 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (4.62.3)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanfordnlp) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanfordnlp) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordnlp) (3.0.4)\n","Installing collected packages: stanfordnlp\n","Successfully installed stanfordnlp-0.2.0\n","Using the default treebank \"en_ewt\" for language \"en\".\n","Would you like to download the models for: en_ewt now? (Y/n)\n","\n","Default download directory: /root/stanfordnlp_resources\n","Hit enter to continue or type an alternate directory.\n","\n","Downloading models for: en_ewt\n","Download location: /root/stanfordnlp_resources/en_ewt_models.zip\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 235M/235M [00:40<00:00, 5.87MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Download complete.  Models saved to: /root/stanfordnlp_resources/en_ewt_models.zip\n","Extracting models file for: en_ewt\n","Cleaning up...Done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"04-sKY__1t58"},"source":["from xml.etree import cElementTree as ET\n","import pandas as pd\n","import string\n","import spacy\n","import re\n","import random\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import csv\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"3gsszVN_1NAJ"},"source":["root_dir = \"/content/drive/MyDrive/NLP Project/Topic 5/\"\n","train_folder = \"Train/SemEval'14-ABSA-TrainData_v2 & AnnotationGuidelines/\"\n","laptop_train_file = \"Laptop_Train_v2.xml\"\n","restaurant_train_file = \"Restaurants_Train_v2.xml\"\n","test_1_folder = \"Test1/ABSA_TestData_PhaseA/ABSA_TestData_PhaseA/\"\n","laptop_test_1_file = \"Laptops_Test_Data_PhaseA.xml\"\n","restaurant_test_1_file = \"Restaurants_Test_Data_PhaseA.xml\"\n","test_2_folder = \"Test2/ABSA_TestData_PhaseB/\"\n","laptop_test_2_file = \"Laptops_Test_Data_phaseB.xml\"\n","restaurant_test_2_file = \"Restaurants_Test_Data_phaseB.xml\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Y6IZZl-QpY3"},"source":["# Data Extraction & Cleaning"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"O8tKAkEGTDgE"},"source":["class AspectWord():\n","    def __init__(self, aspect_term, sentiment_terms, polarity = None):\n","        # Words\n","        self.aspect_term = aspect_term\n","        # List of Words\n","        self.sentiment_terms = sentiment_terms\n","        # Polarity: +,-,neutral\n","        self.polarity = polarity\n","\n","    def __str__(self):\n","        return f\"Aspect Term: {self.aspect_term} Sentiment Terms: {self.sentiment_terms} Polarity: {self.polarity}\"\n","    \n","    def __repr__(self):\n","        return self.__str__()\n","\n","class AspectCategory():\n","    def __init__(self, aspect_category, polarity = None):\n","        # Words\n","        self.aspect_category = aspect_category\n","        # Polarity: +,-,neutral\n","        self.polarity = polarity\n","\n","    def __str__(self):\n","        return f\"Aspect Category: {self.aspect_category} Polarity: {self.polarity}\"\n","    \n","    def __repr__(self):\n","        return self.__str__()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"DEoYTdWZ9Gpr"},"source":["class Sentence():\n","    def __init__(self, sentence_id, sentence, data_type = \"Train\",\n","                 actual_sentence_id = None, actual_aspect_words = [], actual_aspect_categories = []): \n","        # Int\n","        self.sentence_id = sentence_id\n","        # String\n","        self.sentence = sentence\n","        # String\n","        self.data_type = data_type\n","        # String\n","        self.actual_sentence_id = actual_sentence_id\n","        # List of AspectWord\n","        self.actual_aspect_words = actual_aspect_words\n","        # List of AspectWord\n","        self.generated_aspect_words = []\n","        # List of AspectCategory\n","        self.actual_aspect_categories = actual_aspect_categories\n","        # Polarity\n","        self.actual_sentence_polarity = None\n","        # Polarity\n","        self.generated_sentence_polarity = None\n","\n","    def calculate_actual_polarity(self):\n","        temp_polarity = 0\n","        for actual_aspect_word in self.actual_aspect_words:\n","          if(actual_aspect_word.polarity == \"positive\"):\n","            temp_polarity+=1\n","          elif(actual_aspect_word.polarity == \"negative\"):\n","            temp_polarity-=1\n","        if(temp_polarity > 0):\n","          self.actual_sentence_polarity = \"positive\"\n","        elif(temp_polarity < 0):\n","          self.actual_sentence_polarity = \"negative\"\n","        else:\n","          self.actual_sentence_polarity = \"neutral\"\n","\n","    def calculate_generated_polarity(self):\n","        temp_polarity = 0\n","        for generated_aspect_word in self.generated_aspect_words:\n","          if(generated_aspect_word.polarity == \"positive\"):\n","            temp_polarity+=1\n","          elif(generated_aspect_word.polarity == \"negative\"):\n","            temp_polarity-=1\n","        if(temp_polarity > 0):\n","          self.generated_sentence_polarity = \"positive\"\n","        elif(temp_polarity < 0):\n","          self.generated_sentence_polarity = \"negative\"\n","        else:\n","          self.generated_sentence_polarity = \"neutral\"\n","\n","    def __str__(self):\n","        if self.data_type == \"Train\":\n","            return f\"ID: {self.sentence_id} Sentence: {self.sentence} {self.actual_aspect_words}\"\n","        else:\n","            return f\"ID: {self.sentence_id} Sentence: {self.sentence} {self.generated_aspect_words}\"\n","    \n","    def __repr__(self):\n","        return self.__str__()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"BIb2pocS9AiG"},"source":["def xml_to_sentences(path, data_type = \"Train\"):\n","    data = []\n","    tree = ET.parse(path)\n","    root = tree.getroot()\n","    id = 1\n","    for page in root.findall('sentence'):\n","        sentence_id = id\n","        sentence = page[0].text\n","        actual_sentence_id = page.attrib[\"id\"]\n","        actual_aspect_terms = []\n","        actual_polarity = []\n","        if (data_type == \"Train\"):\n","            if len(page)> 1 and page[1].tag == \"aspectTerms\":\n","                aspect_terms_data = [x.attrib for x in page[1]]\n","                aspect_categories_data = None\n","                \n","                # Ignore Sentences without aspect terms if training data\n","                aspect_words = []\n","                for x in aspect_terms_data:\n","                    aspect_words.append(AspectWord(x['term'],[],x['polarity']))\n","\n","                aspect_categories = []\n","                if len(page) > 2:\n","                    aspect_categories_data = [x.attrib for x in page[2]]\n","                    for x in aspect_categories_data:\n","                        aspect_categories.append(AspectWord(x['category'],x['polarity']))\n","                id += 1\n","                curr_sentence = Sentence(sentence_id, sentence, data_type, actual_sentence_id, aspect_words, aspect_categories)\n","                curr_sentence.calculate_actual_polarity()\n","                data.append(curr_sentence)\n","        elif (data_type == \"Test-2\"):\n","            if len(page)> 1 and page[1].tag == \"aspectTerms\":\n","                aspect_terms_data = [x.attrib for x in page[1]]\n","                aspect_categories_data = None\n","                \n","                # Ignore Sentences without aspect terms if training data\n","                aspect_words = []\n","                for x in aspect_terms_data:\n","                    aspect_words.append(AspectWord(x['term'],[]))\n","\n","                aspect_categories = []\n","                if len(page) > 2:\n","                    aspect_categories_data = [x.attrib for x in page[2]]\n","                    for x in aspect_categories_data:\n","                        aspect_categories.append(AspectWord(x['category'],[]))\n","                id += 1\n","                curr_sentence = Sentence(sentence_id, sentence, data_type, actual_sentence_id, aspect_words, aspect_categories)\n","                curr_sentence.calculate_actual_polarity()\n","                data.append(curr_sentence)\n","        elif (data_type == \"Test\"):\n","            curr_sentence = Sentence(sentence_id, sentence, data_type, actual_sentence_id)\n","            data.append(curr_sentence)\n","            id += 1\n","        else:\n","            print(\"Incorrect Data Type\")\n","            return None\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"R3gJ47H_EAw-"},"source":["def data_list_to_df(data_list, aspect_terms = \"actual\", aspect_polarity = True, no_of_rows = 5):\n","    \n","    data = pd.DataFrame(columns = [\"ID\",\"Sentence\",\"Actual Aspect Terms\",\"Actual Sentiment Terms\",\"Actual Polarities\",\"Generated Aspect Terms\",\"Generated Sentiment Terms\",\"Generated Polarities\"])\n","    \n","    for i in range(min(len(data_list), no_of_rows)):\n","        data.loc[len(data.index)] = [data_list[i].sentence_id, data_list[i].sentence, [x.aspect_term for x in data_list[i].actual_aspect_words], [x.sentiment_terms for x in data_list[i].actual_aspect_words], [x.polarity for x in data_list[i].actual_aspect_words], [x.aspect_term for x in data_list[i].generated_aspect_words], [x.sentiment_terms for x in data_list[i].generated_aspect_words], [x.polarity for x in data_list[i].generated_aspect_words]] \n","    \n","    if aspect_terms == \"actual\":\n","        data.drop([\"Generated Aspect Terms\",\"Generated Sentiment Terms\",\"Generated Polarities\",\"Actual Sentiment Terms\"], axis = 1, inplace = True)\n","    elif aspect_terms == \"generated\":\n","        data.drop([\"Actual Aspect Terms\",\"Actual Sentiment Terms\",\"Actual Polarities\"], axis = 1, inplace = True)\n","    elif aspect_terms == \"none\":\n","        data.drop([\"Generated Aspect Terms\",\"Generated Sentiment Terms\",\"Generated Polarities\",\"Actual Aspect Terms\",\"Actual Sentiment Terms\",\"Actual Polarities\"], axis = 1, inplace = True)\n","\n","    if not aspect_polarity:\n","        try:\n","            data.drop([\"Generated Polarities\"],axis=1, inplace = True)\n","        except:\n","            pass\n","        try:\n","            data.drop([\"Actual Polarities\"],axis=1, inplace = True)\n","        except:\n","            pass\n","\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9yUW3JYsyg0"},"source":["# Find Aspect Terms"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Mv7_H0EAQxOC","outputId":"585039d8-000d-4aa6-a4b1-492be40536d4"},"source":["nlp = stanfordnlp.Pipeline()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Use device: cpu\n","---\n","Loading: tokenize\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","---\n","Loading: pos\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","---\n","Loading: lemma\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","Building an attentional Seq2Seq model...\n","Using a Bi-LSTM encoder\n","Using soft attention for LSTM.\n","Finetune all embeddings.\n","[Running seq2seq lemmatizer with edit classifier]\n","---\n","Loading: depparse\n","With settings: \n","{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n","Done loading processors!\n","---\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"aaNQFY8cqUm1"},"source":["def extract_attributes(text):\n","    doc = nlp(text)\n","    parsed_text = {'word':[], 'lemma':[], 'pos':[], 'dep':[], 'gov':[], 'gov_pos':[]}\n","    for sent in doc.sentences:\n","        for wrd in sent.words:\n","            parsed_text['word'].append(wrd.text)\n","            parsed_text['lemma'].append(wrd.lemma)\n","            parsed_text['pos'].append(wrd.pos)\n","            parsed_text['dep'].append(wrd.dependency_relation)\n","    for sent in doc.sentences:\n","        for wrd in sent.words:        \n","            if wrd.governor == 0:\n","                parsed_text['gov'].append(\"ROOT\")\n","                parsed_text['gov_pos'].append(\"-\")\n","            else:   \n","                parsed_text['gov'].append(parsed_text['word'][wrd.governor-1])\n","                parsed_text['gov_pos'].append(parsed_text['pos'][wrd.governor-1])\n","    \n","    return pd.DataFrame(parsed_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"bu7SkTslyip8","outputId":"389c5207-4aae-4bed-97fd-a13349e67e02"},"source":["text = \"have keep turning until decides lower mute\"\n","extract_attributes(text)"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>lemma</th>\n","      <th>pos</th>\n","      <th>dep</th>\n","      <th>gov</th>\n","      <th>gov_pos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>have</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>aux</td>\n","      <td>turning</td>\n","      <td>VBG</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>keep</td>\n","      <td>keep</td>\n","      <td>NN</td>\n","      <td>nsubj</td>\n","      <td>turning</td>\n","      <td>VBG</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>turning</td>\n","      <td>turn</td>\n","      <td>VBG</td>\n","      <td>root</td>\n","      <td>ROOT</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>until</td>\n","      <td>until</td>\n","      <td>IN</td>\n","      <td>mark</td>\n","      <td>decides</td>\n","      <td>VBZ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>decides</td>\n","      <td>decide</td>\n","      <td>VBZ</td>\n","      <td>advcl</td>\n","      <td>turning</td>\n","      <td>VBG</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>lower</td>\n","      <td>lower</td>\n","      <td>JJR</td>\n","      <td>amod</td>\n","      <td>mute</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>mute</td>\n","      <td>mute</td>\n","      <td>NN</td>\n","      <td>obj</td>\n","      <td>decides</td>\n","      <td>VBZ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      word   lemma  pos    dep      gov gov_pos\n","0     have    have  VBP    aux  turning     VBG\n","1     keep    keep   NN  nsubj  turning     VBG\n","2  turning    turn  VBG   root     ROOT       -\n","3    until   until   IN   mark  decides     VBZ\n","4  decides  decide  VBZ  advcl  turning     VBG\n","5    lower   lower  JJR   amod     mute      NN\n","6     mute    mute   NN    obj  decides     VBZ"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"0kC4ChZC9SMm"},"source":["def parse_compound_aspects(data):\n","    count = 0\n","    for i in range(len(data)):\n","        j = 0\n","        generated_aspect_words_to_be_deleted = set()\n","        while(j < len(data[i].generated_aspect_words)):\n","            generated_aspect_term = data[i].generated_aspect_words[j].aspect_term\n","            individual_aspect_terms = generated_aspect_term.split(\" \")\n","            if(len(individual_aspect_terms) > 1):\n","                for individual_aspect_term in individual_aspect_terms:\n","                    k = 0\n","                    while(k < len(data[i].generated_aspect_words)):\n","                        if k == j:\n","                            k += 1\n","                            continue\n","                        if individual_aspect_term == data[i].generated_aspect_words[k].aspect_term:\n","                            data[i].generated_aspect_words[j].sentiment_terms += (data[i].generated_aspect_words[k].sentiment_terms)\n","                            generated_aspect_words_to_be_deleted.add(data[i].generated_aspect_words[k])\n","                            count += 1\n","                        k += 1\n","            j += 1\n","        for generated_aspect_word_to_be_deleted in generated_aspect_words_to_be_deleted:\n","            data[i].generated_aspect_words.remove(generated_aspect_word_to_be_deleted)\n","    return count\n","\n","def add_or_update_aspect_word(sentence, aspect_term, sentiment_term):\n","    if sentiment_term == None:\n","        sentence.generated_aspect_words.append(AspectWord(aspect_term, []))\n","        return True\n","    for i in range(len(sentence.generated_aspect_words)):\n","        if sentence.generated_aspect_words[i].aspect_term == aspect_term:\n","            sentence.generated_aspect_words[i].sentiment_terms.append(sentiment_term)\n","            return True\n","\n","    sentence.generated_aspect_words.append(AspectWord(aspect_term, [sentiment_term]))\n","    return True\n","\n","def generate_aspect_words(data):\n","        \n","    for i in range(len(data)):\n","        extracted_attributes_df = extract_attributes(data[i].sentence)\n","        data[i].generated_aspect_words.clear()\n","\n","        # Rules:\n","        for j in extracted_attributes_df.index:\n","            \n","            # Bell, based in Los Angeles, makes and distributes electronic, computer and building products.\n","            if extracted_attributes_df['dep'][j] == \"nsubj\":\n","                # Example: (best, display)\n","                if extracted_attributes_df['gov_pos'][j] in [\"JJ\", \"JJR\", \"JJS\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                # Example: (distributes, XYZ Company)\n","                elif extracted_attributes_df['gov_pos'][j] in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                \n","            elif extracted_attributes_df['dep'][j] == \"amod\":\n","                # Example: (products, electronic)\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"JJ\", \"JJR\", \"JJS\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                # Example: (products, building)\n","                elif extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                \n","            elif extracted_attributes_df['dep'][j] == \"obj\":\n","                # Example: (makes, products)\n","                if extracted_attributes_df['gov_pos'][j] in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                    \n","            elif extracted_attributes_df['dep'][j] == \"nmod\":\n","                # Both are aspects\n","                # Example: (display, computer)\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NS\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j], None)\n","                    \n","                elif extracted_attributes_df['gov_pos'][j] in [\"JJ\"] and extracted_attributes_df['pos'][j] in [\"NN\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j], extracted_attributes_df['gov'][j])\n","                    \n","            elif extracted_attributes_df['dep'][j] == \"acl\":\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"JJ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                \n","                elif extracted_attributes_df['gov_pos'][j] in [\"NNS\"] and extracted_attributes_df['pos'][j] in [\"VBP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                \n","            elif extracted_attributes_df['dep'][j] == \"conj\":\n","                # Both are aspects\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"NN\", \"NNS\", \"NNP\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j], None)\n","\n","                elif extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"JJ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                    \n","                elif extracted_attributes_df['gov_pos'][j] in [\"NN\", \"NNS\", \"NNP\"] and extracted_attributes_df['pos'][j] in [\"VBZ\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['gov'][j], extracted_attributes_df['word'][j])\n","                    \n","            elif extracted_attributes_df['dep'][j] == \"compound\":\n","                # Both are aspects\n","                if extracted_attributes_df['gov_pos'][j] in [\"NN\"] and extracted_attributes_df['pos'][j] in [\"NN\"]:\n","                    add_or_update_aspect_word(data[i], extracted_attributes_df['word'][j] + \" \" + extracted_attributes_df['gov'][j], None)\n","                    \n","    parse_compound_aspects(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1b0dEF69dbm"},"source":["# Aspect Term Extraction Performance"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"VQnzE7xzeot_"},"source":["def match_aspect_terms(actual_aspect_term, generated_aspect_term):\n","    n = len(generated_aspect_term.split(\" \"))\n","    for i in range(n):\n","        temp = generated_aspect_term.split(\" \",maxsplit = i)\n","        if len(temp) > 1:\n","            rest = temp[1]\n","        else:\n","            rest = temp[0]\n","        if re.search(rest, actual_aspect_term):\n","            return len(rest)/len(actual_aspect_term)\n","        generated_aspect_term = rest\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"2fR9eSBUA03s"},"source":["def aspect_term_performance(data):\n","    true_positives = 0\n","    false_positives = 0\n","    no_of_actual_aspect_terms = 0\n","    no_of_generated_aspect_terms = 0\n","\n","    for i in range(len(data)):\n","        no_of_generated_aspect_terms += len(data[i].generated_aspect_words)\n","        no_of_actual_aspect_terms += len(data[i].actual_aspect_words)\n","        for generated_aspect_word in data[i].generated_aspect_words:\n","            found = False\n","            for actual_aspect_word in data[i].actual_aspect_words:\n","                matched_part = match_aspect_terms(actual_aspect_word.aspect_term, generated_aspect_word.aspect_term)\n","                if matched_part > 0:\n","                    true_positives += matched_part\n","                    found = True\n","                    break\n","            if not found:\n","                false_positives += 1\n","\n","    ratios = {\"Aspect Term Extraction Precision\": true_positives / no_of_generated_aspect_terms, \"Aspect Term Extraction Recall\":true_positives/no_of_actual_aspect_terms, \"Aspect Term Extraction True Positives\":true_positives, \"Actual Aspect Terms\":no_of_actual_aspect_terms, \"Generated Aspect Terms\":no_of_generated_aspect_terms}\n","    return ratios"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXny_pPTtgsh"},"source":["# Train the Model\n","Make a frequency dictionary for all the Sentiment Words"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"SFMs7p3YtU6j"},"source":["def train(data):\n","    # Do preprocessing if needed\n","    sentiment_terms_frequency = {}\n","    for sentence in data:\n","        for generated_aspect_word in sentence.generated_aspect_words:\n","            polarity = None\n","            for actual_aspect_word in sentence.actual_aspect_words:\n","                matched_part = match_aspect_terms(actual_aspect_word.aspect_term, generated_aspect_word.aspect_term)\n","                if matched_part > 0: \n","                    if actual_aspect_word.polarity == 'positive':\n","                        polarity = 1\n","                    \n","                    elif actual_aspect_word.polarity == 'negative':\n","                        polarity = -1\n","                    \n","                    else:\n","                        polarity = 0\n","                    break    \n","            if polarity ==  None:\n","                continue\n","            for sentiment_term in generated_aspect_word.sentiment_terms:\n","                if sentiment_term in list(sentiment_terms_frequency.keys()): \n","                    sentiment_terms_frequency[sentiment_term]['frequency'] += 1\n","                    sentiment_terms_frequency[sentiment_term]['polarity'] += (polarity)\n","                \n","                else:\n","                    sentiment_terms_frequency[sentiment_term] = {'frequency':1, 'polarity':polarity}\n","\n","    for key in list(sentiment_terms_frequency.keys()):\n","        sentiment_terms_frequency[key] = (sentiment_terms_frequency[key]['polarity']/sentiment_terms_frequency[key]['frequency'])\n","\n","    return sentiment_terms_frequency"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pYWjESWJtw9y"},"source":["# Test the Model"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"-0JS4mxS6UWl"},"source":["def predict(data, sentiment_terms_frequency):\n","    generate_aspect_words(data)\n","    unk_words = set() \n","    for i in range(len(data)):\n","        for j in range(len(data[i].generated_aspect_words)):\n","            sentiment_terms = data[i].generated_aspect_words[j].sentiment_terms\n","            unk = 0\n","            polarity = 0\n","            for term in sentiment_terms:\n","                if term not in sentiment_terms_frequency.keys():\n","                    unk += 1\n","                    unk_words.add(term)\n","                else:\n","                    polarity += sentiment_terms_frequency[term]\n","            if (len(sentiment_terms) - unk != 0):\n","                data[i].generated_aspect_words[j].polarity = polarity/(len(sentiment_terms)-unk)\n","            else:\n","                data[i].generated_aspect_words[j].polarity = 0\n","    return len(unk_words)\n","\n","def find_polarity(value, threshold = 0.2):\n","    if (value < -1*threshold):\n","        return \"negative\"\n","    elif (value > threshold):\n","        return \"positive\"\n","    else:\n","        return \"neutral\"\n","\n","def classify(data, sentiment_terms_frequency):\n","    no_of_unk_words = predict(data, sentiment_terms_frequency)\n","    for i in range(len(data)):\n","        for j in range(len(data[i].generated_aspect_words)):\n","            data[i].generated_aspect_words[j].polarity = find_polarity(data[i].generated_aspect_words[j].polarity)\n","    return no_of_unk_words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4UhcH3uWuLym"},"source":["# Performance of Sentiment Classification"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Ys0Azbo3O_e-"},"source":["# Split data and do this\n","def sentiment_polarity_classification_performance(data):\n","    matches = 0\n","    non_matches = 0\n","    for i in range(len(data)):\n","        for actual_aspect_word in data[i].actual_aspect_words:\n","            actual_aspect_term = actual_aspect_word.aspect_term\n","            actual_polarity = actual_aspect_word.polarity\n","            for generated_aspect_word in data[i].generated_aspect_words:\n","                if (match_aspect_terms(actual_aspect_term, generated_aspect_word.aspect_term) > 0):\n","                    if (actual_polarity == generated_aspect_word.polarity):\n","                        matches+=1\n","                    else:\n","                        non_matches+=1\n","                    break\n","\n","    return {\"Sentiment Polarity Matches\":matches, \"Sentiment Polarity Non-Matches\":non_matches, \"Sentiment Polarity Classification Precision\":matches/(matches+non_matches)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzDcHKIal4ZW"},"source":["# Performance of Sentence Polarity Classification"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"k4jef88rl8R4"},"source":["def sentence_polarity_classification_performance(data): \n","    matches = 0\n","    non_matches = 0\n","    for i in range(len(data)):\n","        data[i].calculate_generated_polarity()\n","        if(data[i].actual_sentence_polarity == data[i].generated_sentence_polarity):\n","            matches+=1\n","        else:\n","            non_matches+=1\n","\n","    return {\"Sentence Polarity Matches\":matches, \"Sentence Polarity Non Matches\":non_matches, \"Sentence Polarity Classification Precision\":matches/(matches+non_matches)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pt4a5egK62y2"},"source":["# Execution"]},{"cell_type":"markdown","metadata":{"id":"RAFzpOAKB9cb"},"source":["## Load Data and Generate Aspect Terms"]},{"cell_type":"markdown","metadata":{"id":"temFNNOcAmpF"},"source":["### Laptop"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"R_bW8EQv1o_d","outputId":"6bceb224-aea8-432b-8cc8-4cfce06103f3"},"source":["laptop_train_data = xml_to_sentences(root_dir + train_folder + laptop_train_file)\n","laptop_train_data_size = len(laptop_train_data)\n","print(f\"Total sentences: {laptop_train_data_size}\")\n","laptop_train_data_df = data_list_to_df(laptop_train_data, aspect_terms = \"actual\", aspect_polarity = True)\n","laptop_train_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Total sentences: 1488\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Actual Aspect Terms</th>\n","      <th>Actual Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>I charge it at night and skip taking the cord ...</td>\n","      <td>[cord, battery life]</td>\n","      <td>[neutral, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>The tech guy then said the service center does...</td>\n","      <td>[service center, \"sales\" team, tech guy]</td>\n","      <td>[negative, negative, neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>it is of high quality, has a killer GUI, is ex...</td>\n","      <td>[quality, GUI, applications, use]</td>\n","      <td>[positive, positive, positive, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Easy to start up and does not overheat as much...</td>\n","      <td>[start up]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>I even got my teenage son one, because of the ...</td>\n","      <td>[features, iChat, Photobooth, garage band]</td>\n","      <td>[positive, positive, positive, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...                         Actual Polarities\n","0  1  ...                       [neutral, positive]\n","1  2  ...             [negative, negative, neutral]\n","2  3  ...  [positive, positive, positive, positive]\n","3  4  ...                                [positive]\n","4  5  ...  [positive, positive, positive, positive]\n","\n","[5 rows x 4 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"OvksVdL85A9I","outputId":"25cd8597-5b8d-4255-9fbd-90385163fe51"},"source":["# Split into train and validation\n","np.random.seed(7)\n","random.seed(9)\n","laptop_train_data, laptop_valid_data = sklearn.model_selection.train_test_split(laptop_train_data, test_size=0.1)\n","print(f\"Size of Training Data: {len(laptop_train_data)}\\nSize of Validation Data: {len(laptop_valid_data)}\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Size of Training Data: 1339\n","Size of Validation Data: 149\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"B54ACZ0ADxbJ","outputId":"25fb7745-399a-4404-a1c5-a7758b209104"},"source":["generate_aspect_words(laptop_train_data)\n","laptop_train_data_df = data_list_to_df(laptop_train_data, aspect_terms = \"generated\", aspect_polarity = True)\n","laptop_train_data_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>611</td>\n","      <td>Not only are the versions of these programs ab...</td>\n","      <td>[versions]</td>\n","      <td>[[worked, able, superior]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>260</td>\n","      <td>Sometimes you really have to tap the pad to ge...</td>\n","      <td>[pad]</td>\n","      <td>[[tap]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>799</td>\n","      <td>-When battery life went to 4 hours or less, to...</td>\n","      <td>[battery life]</td>\n","      <td>[[went]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>397</td>\n","      <td>If you don't feel comfortable doing it yoursel...</td>\n","      <td>[case, one, Buy]</td>\n","      <td>[[buy], [white, bought], [Best]]</td>\n","      <td>[None, None, None]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>834</td>\n","      <td>/ awesome cooling system/ much better grafics ...</td>\n","      <td>[cooling system, card, GB RAM, RAM screen, bac...</td>\n","      <td>[[awesome], [better], [], [LED], [LED], [LED, ...</td>\n","      <td>[None, None, None, None, None, None]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    ID  ...                  Generated Polarities\n","0  611  ...                                [None]\n","1  260  ...                                [None]\n","2  799  ...                                [None]\n","3  397  ...                    [None, None, None]\n","4  834  ...  [None, None, None, None, None, None]\n","\n","[5 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"w49l-LwWGc23","outputId":"c062b8c6-1afa-4e02-b422-fc5457c8bd04"},"source":["laptop_train_data_ratios = aspect_term_performance(laptop_train_data)\n","pd.DataFrame.from_dict(laptop_train_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.419667</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.566810</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>1191.433998</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>2102.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>2839.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        Parameters\n","Aspect Term Extraction Precision          0.419667\n","Aspect Term Extraction Recall             0.566810\n","Aspect Term Extraction True Positives  1191.433998\n","Actual Aspect Terms                    2102.000000\n","Generated Aspect Terms                 2839.000000"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"R4M4ChH-Ao32"},"source":["### Restaurant"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"3Fm9J86cAqPA","outputId":"581f13a6-b5be-436b-d052-0970f2123b95"},"source":["restaurant_train_data = xml_to_sentences(root_dir + train_folder + restaurant_train_file)\n","restaurant_train_data_size = len(restaurant_train_data)\n","print(f\"Total sentences: {restaurant_train_data_size}\")\n","restaurant_train_data_df = data_list_to_df(restaurant_train_data, aspect_terms = \"actual\", aspect_polarity = True)\n","restaurant_train_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Total sentences: 2021\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Actual Aspect Terms</th>\n","      <th>Actual Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>But the staff was so horrible to us.</td>\n","      <td>[staff]</td>\n","      <td>[negative]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>To be completely fair, the only redeeming fact...</td>\n","      <td>[food]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>The food is uniformly exceptional, with a very...</td>\n","      <td>[food, kitchen, menu]</td>\n","      <td>[positive, positive, neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Not only was the food outstanding, but the lit...</td>\n","      <td>[food, perks]</td>\n","      <td>[positive, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Our agreed favorite is the orrechiete with sau...</td>\n","      <td>[orrechiete with sausage and chicken, waiters,...</td>\n","      <td>[positive, positive, neutral, neutral]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...                       Actual Polarities\n","0  1  ...                              [negative]\n","1  2  ...                              [positive]\n","2  3  ...           [positive, positive, neutral]\n","3  4  ...                    [positive, positive]\n","4  5  ...  [positive, positive, neutral, neutral]\n","\n","[5 rows x 4 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"GINwTBiUBBV9","outputId":"be9749c7-4d7e-4406-fa3f-41a4e5461a71"},"source":["# Split into train and validation\n","np.random.seed(7)\n","random.seed(9)\n","restaurant_train_data, restaurant_valid_data = sklearn.model_selection.train_test_split(restaurant_train_data, test_size=0.1)\n","print(f\"Size of Training Data: {len(restaurant_train_data)}\\nSize of Validation Data: {len(restaurant_valid_data)}\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Size of Training Data: 1818\n","Size of Validation Data: 203\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"o8v6x7aBBTyg","outputId":"2a346bb0-345f-4a19-e18d-aec9ff9b5db0"},"source":["generate_aspect_words(restaurant_train_data)\n","restaurant_train_data_df = data_list_to_df(restaurant_train_data, aspect_terms = \"generated\", aspect_polarity = True)\n","restaurant_train_data_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1706</td>\n","      <td>I had the mango chicken and i can't go on to t...</td>\n","      <td>[mango chicken, presentation]</td>\n","      <td>[[had], [beatiful]]</td>\n","      <td>[None, None]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1987</td>\n","      <td>I've had the chicken with garlic sauce, chicke...</td>\n","      <td>[garlic sauce, sauce chicken, chicken sauce, b...</td>\n","      <td>[[black], [black, had], [had, black], [black],...</td>\n","      <td>[None, None, None, None, None, None, None]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>652</td>\n","      <td>My friend got the mushroom pizza which tasted ...</td>\n","      <td>[friend, mushroom pizza]</td>\n","      <td>[[got], [got]]</td>\n","      <td>[None, None]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>142</td>\n","      <td>What came to our table was burned beyond recog...</td>\n","      <td>[recognition]</td>\n","      <td>[[stringy]]</td>\n","      <td>[None]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>354</td>\n","      <td>otherwise, good stuff for late nite eats.</td>\n","      <td>[stuff, eats]</td>\n","      <td>[[good], [late]]</td>\n","      <td>[None, None]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     ID  ...                        Generated Polarities\n","0  1706  ...                                [None, None]\n","1  1987  ...  [None, None, None, None, None, None, None]\n","2   652  ...                                [None, None]\n","3   142  ...                                      [None]\n","4   354  ...                                [None, None]\n","\n","[5 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"9OtPhTTEr1xd","outputId":"0f6c721f-60d9-47b0-c4f5-c507e6528f8b"},"source":["restaurant_train_data_ratios = aspect_term_performance(restaurant_train_data)\n","pd.DataFrame.from_dict(restaurant_train_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.571080</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.642768</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>2114.707670</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>3290.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>3703.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        Parameters\n","Aspect Term Extraction Precision          0.571080\n","Aspect Term Extraction Recall             0.642768\n","Aspect Term Extraction True Positives  2114.707670\n","Actual Aspect Terms                    3290.000000\n","Generated Aspect Terms                 3703.000000"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"lEG72HsL7syV"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"OPD-yMh9DuEE"},"source":["### Laptop"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"f8vHItHDD3Gx","outputId":"581ca282-cd09-48c2-9101-68e2ebc6b120"},"source":["laptop_sentiment_terms_frequency_train = train(laptop_train_data)\n","print(f\"Number of Sentiment Terms: {len(laptop_sentiment_terms_frequency_train)}\")\n","df = pd.DataFrame.from_dict(laptop_sentiment_terms_frequency_train, orient = 'index', columns =[\"Polarity\"])\n","df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Sentiment Terms: 615\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tap</th>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>went</th>\n","      <td>-0.833333</td>\n","    </tr>\n","    <tr>\n","      <th>buy</th>\n","      <td>-0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>awesome</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>better</th>\n","      <td>0.142857</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Polarity\n","tap     -1.000000\n","went    -0.833333\n","buy     -0.333333\n","awesome  1.000000\n","better   0.142857"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"iiF4gSSMDwow"},"source":["### Restaurant"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"8YSxseieD-lV","outputId":"67576a94-d319-4e89-9b2f-927e87c0fad9"},"source":["restaurant_sentiment_terms_frequency_train = train(restaurant_train_data)\n","print(f\"Number of Sentiment Terms: {len(restaurant_sentiment_terms_frequency_train)}\")\n","df = pd.DataFrame.from_dict(restaurant_sentiment_terms_frequency_train, orient = 'index', columns =[\"Polarity\"])\n","df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Sentiment Terms: 853\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>had</th>\n","      <td>0.406977</td>\n","    </tr>\n","    <tr>\n","      <th>beatiful</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>black</th>\n","      <td>0.363636</td>\n","    </tr>\n","    <tr>\n","      <th>got</th>\n","      <td>0.714286</td>\n","    </tr>\n","    <tr>\n","      <th>good</th>\n","      <td>0.816327</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Polarity\n","had       0.406977\n","beatiful  1.000000\n","black     0.363636\n","got       0.714286\n","good      0.816327"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"s_GKxyZ-DzXu"},"source":["### Mixed"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"f9CeSkQu9v9P","outputId":"38332b29-cc7b-46c8-bba6-eea3f41ffdf4"},"source":["mixed_sentiment_terms_frequency_train = train(laptop_train_data + restaurant_train_data)\n","print(f\"Number of Sentiment Terms: {len(mixed_sentiment_terms_frequency_train)}\")\n","df = pd.DataFrame.from_dict(mixed_sentiment_terms_frequency_train, orient = 'index', columns =[\"Polarity\"])\n","df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Sentiment Terms: 1251\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tap</th>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>went</th>\n","      <td>-0.833333</td>\n","    </tr>\n","    <tr>\n","      <th>buy</th>\n","      <td>-0.272727</td>\n","    </tr>\n","    <tr>\n","      <th>awesome</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>better</th>\n","      <td>0.166667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Polarity\n","tap     -1.000000\n","went    -0.833333\n","buy     -0.272727\n","awesome  1.000000\n","better   0.166667"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"rW9abpl_7pqZ"},"source":["## Validation"]},{"cell_type":"markdown","metadata":{"id":"W_5DDsEfCrIu"},"source":["### Laptop"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"RSweiDRCqo-s","outputId":"a0cfbab1-699b-44e0-aecb-d4e8e1803afd"},"source":["laptop_valid_data_predictions_unk_count = classify(laptop_valid_data, mixed_sentiment_terms_frequency_train)\n","# laptop_valid_data_predictions_unk_count = classify(laptop_valid_data, laptop_sentiment_terms_frequency_train)\n","print(\"Unknown Sentiment Terms:\", laptop_valid_data_predictions_unk_count)\n","laptop_valid_data_df = data_list_to_df(laptop_valid_data, aspect_terms = \"none\", aspect_polarity = False)\n","laptop_valid_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Terms: 66\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>433</td>\n","      <td>WHEN TYPING, LETTERS AND SPACES ARE FREQUENTLY...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>59</td>\n","      <td>I love the glass touchpad.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1021</td>\n","      <td>Later it held zero charge and its replacemen...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>678</td>\n","      <td>This computer is exceptionally thin for it's s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1319</td>\n","      <td>It has just enough RAM to run smoothly and eno...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     ID                                           Sentence\n","0   433  WHEN TYPING, LETTERS AND SPACES ARE FREQUENTLY...\n","1    59                         I love the glass touchpad.\n","2  1021    Later it held zero charge and its replacemen...\n","3   678  This computer is exceptionally thin for it's s...\n","4  1319  It has just enough RAM to run smoothly and eno..."]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ttq7OdZduUp7","outputId":"3188a578-eb59-431b-885e-1a1304490940"},"source":["laptop_valid_data_ratios = aspect_term_performance(laptop_valid_data)\n","laptop_valid_data_ratios.update(sentiment_polarity_classification_performance(laptop_valid_data))\n","laptop_valid_data_ratios.update(sentence_polarity_classification_performance(laptop_valid_data))\n","pd.DataFrame.from_dict(laptop_valid_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.467085</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.607576</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>155.539348</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>256.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>333.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Polarity Matches</th>\n","      <td>91.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Polarity Non-Matches</th>\n","      <td>78.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Polarity Classification Precision</th>\n","      <td>0.538462</td>\n","    </tr>\n","    <tr>\n","      <th>Sentence Polarity Matches</th>\n","      <td>65.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentence Polarity Non Matches</th>\n","      <td>84.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentence Polarity Classification Precision</th>\n","      <td>0.436242</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             Parameters\n","Aspect Term Extraction Precision               0.467085\n","Aspect Term Extraction Recall                  0.607576\n","Aspect Term Extraction True Positives        155.539348\n","Actual Aspect Terms                          256.000000\n","Generated Aspect Terms                       333.000000\n","Sentiment Polarity Matches                    91.000000\n","Sentiment Polarity Non-Matches                78.000000\n","Sentiment Polarity Classification Precision    0.538462\n","Sentence Polarity Matches                     65.000000\n","Sentence Polarity Non Matches                 84.000000\n","Sentence Polarity Classification Precision     0.436242"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"b0QEToxlC2fs"},"source":["### Restaurant"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"v4Yz6ToDC7k7","outputId":"b15a5cd0-6023-4072-8f21-6daaa9c3074a"},"source":["restaurant_valid_data_predictions_unk_count = classify(restaurant_valid_data, mixed_sentiment_terms_frequency_train)\n","# restaurant_valid_data_predictions_unk_count = classify(restaurant_valid_data, restaurant_sentiment_terms_frequency_train)\n","print(\"Unknown Sentiment Terms:\", restaurant_valid_data_predictions_unk_count)\n","restaurant_valid_data_df = data_list_to_df(restaurant_valid_data, aspect_terms = \"none\", aspect_polarity = False)\n","restaurant_valid_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Terms: 78\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1396</td>\n","      <td>Their sushi, Kamikaze and other Rolls are fres...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>141</td>\n","      <td>I had very high expectations for this place an...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>111</td>\n","      <td>Pizza and garlic knots are great as well, I or...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>638</td>\n","      <td>No free drink.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>702</td>\n","      <td>I tend to judge a sushi restaurant by its sea ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     ID                                           Sentence\n","0  1396  Their sushi, Kamikaze and other Rolls are fres...\n","1   141  I had very high expectations for this place an...\n","2   111  Pizza and garlic knots are great as well, I or...\n","3   638                                     No free drink.\n","4   702  I tend to judge a sushi restaurant by its sea ..."]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"r_rZgqzCDEre","outputId":"9b8436d2-1941-4a4c-9720-7a694960955b"},"source":["restaurant_valid_data_ratios = aspect_term_performance(restaurant_valid_data)\n","restaurant_valid_data_ratios.update(sentiment_polarity_classification_performance(restaurant_valid_data))\n","restaurant_valid_data_ratios.update(sentence_polarity_classification_performance(restaurant_valid_data))\n","pd.DataFrame.from_dict(restaurant_valid_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.601044</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.675615</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>272.272819</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>403.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>453.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Polarity Matches</th>\n","      <td>161.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Polarity Non-Matches</th>\n","      <td>120.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Polarity Classification Precision</th>\n","      <td>0.572954</td>\n","    </tr>\n","    <tr>\n","      <th>Sentence Polarity Matches</th>\n","      <td>123.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentence Polarity Non Matches</th>\n","      <td>80.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sentence Polarity Classification Precision</th>\n","      <td>0.605911</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             Parameters\n","Aspect Term Extraction Precision               0.601044\n","Aspect Term Extraction Recall                  0.675615\n","Aspect Term Extraction True Positives        272.272819\n","Actual Aspect Terms                          403.000000\n","Generated Aspect Terms                       453.000000\n","Sentiment Polarity Matches                   161.000000\n","Sentiment Polarity Non-Matches               120.000000\n","Sentiment Polarity Classification Precision    0.572954\n","Sentence Polarity Matches                    123.000000\n","Sentence Polarity Non Matches                 80.000000\n","Sentence Polarity Classification Precision     0.605911"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"61HVaA2Z7iUw"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"rbvSn9LzDM9o"},"source":["### Laptop"]},{"cell_type":"markdown","metadata":{"id":"FalPn8dYFFpa"},"source":["#### Test-1 Data"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"4Ow5AwcMCNmN","outputId":"72de9e7b-92ce-4635-a0bd-91c16aa42b55"},"source":["laptop_test_1_data = xml_to_sentences(root_dir + test_1_folder + laptop_test_1_file, data_type = \"Test\")\n","laptop_test_1_data_df = data_list_to_df(laptop_test_1_data, aspect_terms = \"none\", aspect_polarity = False)\n","laptop_test_1_data_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Boot time is super fast, around anywhere from ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>tech support would not fix the problem unless ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>but in resume this computer rocks!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Set up was easy.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID                                           Sentence\n","0  1  Boot time is super fast, around anywhere from ...\n","1  2  tech support would not fix the problem unless ...\n","2  3                 but in resume this computer rocks!\n","3  4                                   Set up was easy.\n","4  5  Did not enjoy the new Windows 8 and touchscree..."]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ZzwFWk-WFZdY","outputId":"7ba4662a-1dab-43ab-f79e-3545034f13e2"},"source":["laptop_test_1_predictions_unk_count = classify(laptop_test_1_data, mixed_sentiment_terms_frequency_train)\n","print(\"Number of Unknown Sentiment Terms:\", laptop_test_1_predictions_unk_count)\n","laptop_test_1_data_df = data_list_to_df(laptop_test_1_data, aspect_terms = \"generated\", aspect_polarity = True)\n","laptop_test_1_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Unknown Sentiment Terms: 202\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Boot time is super fast, around anywhere from ...</td>\n","      <td>[Boot time]</td>\n","      <td>[[fast]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>tech support would not fix the problem unless ...</td>\n","      <td>[tech support, problem, plan]</td>\n","      <td>[[fix], [fix], [bought]]</td>\n","      <td>[negative, negative, negative]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>but in resume this computer rocks!</td>\n","      <td>[computer]</td>\n","      <td>[[rocks]]</td>\n","      <td>[neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Set up was easy.</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n","      <td>[functions, Windows]</td>\n","      <td>[[new, enjoy], [enjoy]]</td>\n","      <td>[positive, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...            Generated Polarities\n","0  1  ...                      [positive]\n","1  2  ...  [negative, negative, negative]\n","2  3  ...                       [neutral]\n","3  4  ...                              []\n","4  5  ...            [positive, positive]\n","\n","[5 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"xufz46qnFTIT"},"source":["#### Test-2 Data"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"p46xJnlCFTIU","outputId":"f062fb20-6750-465a-a84d-75323bf45fc2"},"source":["laptop_test_2_data = xml_to_sentences(root_dir + test_2_folder + laptop_test_2_file, data_type = \"Test-2\")\n","laptop_test_2_data_df = data_list_to_df(laptop_test_2_data, aspect_terms = \"none\", aspect_polarity = False)\n","laptop_test_2_data_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Boot time is super fast, around anywhere from ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>tech support would not fix the problem unless ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Set up was easy.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Other than not being a fan of click pads (indu...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID                                           Sentence\n","0  1  Boot time is super fast, around anywhere from ...\n","1  2  tech support would not fix the problem unless ...\n","2  3                                   Set up was easy.\n","3  4  Did not enjoy the new Windows 8 and touchscree...\n","4  5  Other than not being a fan of click pads (indu..."]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"EvstHHYPFTIV","outputId":"0b7189a3-1bfa-4687-f2f1-62968a278ade"},"source":["laptop_test_2_predictions_unk_count = classify(laptop_test_2_data, mixed_sentiment_terms_frequency_train)\n","print(\"Number of Unknown Sentiment Terms:\", laptop_test_2_predictions_unk_count)\n","laptop_test_2_data_df = data_list_to_df(laptop_test_2_data, aspect_terms = \"both\", aspect_polarity = True)\n","laptop_test_2_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Unknown Sentiment Terms: 127\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Actual Aspect Terms</th>\n","      <th>Actual Sentiment Terms</th>\n","      <th>Actual Polarities</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Boot time is super fast, around anywhere from ...</td>\n","      <td>[Boot time]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[Boot time]</td>\n","      <td>[[fast]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>tech support would not fix the problem unless ...</td>\n","      <td>[tech support]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[tech support, problem, plan]</td>\n","      <td>[[fix], [fix], [bought]]</td>\n","      <td>[negative, negative, negative]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Set up was easy.</td>\n","      <td>[Set up]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n","      <td>[Windows 8, touchscreen functions]</td>\n","      <td>[[], []]</td>\n","      <td>[None, None]</td>\n","      <td>[functions, Windows]</td>\n","      <td>[[new, enjoy], [enjoy]]</td>\n","      <td>[positive, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Other than not being a fan of click pads (indu...</td>\n","      <td>[internal speakers, price tag, click pads]</td>\n","      <td>[[], [], []]</td>\n","      <td>[None, None, None]</td>\n","      <td>[industry standard, speakers, things, price tag]</td>\n","      <td>[[], [lousy, internal], [find], [considering]]</td>\n","      <td>[neutral, neutral, neutral, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...                   Generated Polarities\n","0  1  ...                             [positive]\n","1  2  ...         [negative, negative, negative]\n","2  3  ...                                     []\n","3  4  ...                   [positive, positive]\n","4  5  ...  [neutral, neutral, neutral, positive]\n","\n","[5 rows x 8 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"pXFZqyBacRVS","outputId":"b7abf3b7-cc90-44d4-dabd-9e496b21ae3e"},"source":["laptop_test_2_data_ratios = aspect_term_performance(laptop_test_2_data)\n","pd.DataFrame.from_dict(laptop_test_2_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.464897</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.545224</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>356.576322</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>654.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>767.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       Parameters\n","Aspect Term Extraction Precision         0.464897\n","Aspect Term Extraction Recall            0.545224\n","Aspect Term Extraction True Positives  356.576322\n","Actual Aspect Terms                    654.000000\n","Generated Aspect Terms                 767.000000"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"RdCzTZwgFiJ_"},"source":["### Restaurant"]},{"cell_type":"markdown","metadata":{"id":"hBwuyvUzFiKA"},"source":["#### Test-1 Data"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"C-8HOLGKFiKB","outputId":"d9ab74ef-373c-4401-c9e9-fc8742abbb3a"},"source":["restaurant_test_1_data = xml_to_sentences(root_dir + test_1_folder + restaurant_test_1_file, data_type = \"Test\")\n","restaurant_test_1_data_df = data_list_to_df(restaurant_test_1_data, aspect_terms = \"none\", aspect_polarity = False)\n","restaurant_test_1_data_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The bread is top notch as well.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>I have to say they have one of the fastest del...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Food is always fresh and hot- ready to eat!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Did I mention that the coffee is OUTSTANDING?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Certainly not the best sushi in New York, howe...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID                                           Sentence\n","0  1                    The bread is top notch as well.\n","1  2  I have to say they have one of the fastest del...\n","2  3        Food is always fresh and hot- ready to eat!\n","3  4      Did I mention that the coffee is OUTSTANDING?\n","4  5  Certainly not the best sushi in New York, howe..."]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"R9J8ounUFiKC","outputId":"034a8644-16ca-4570-f4b4-b0f06a762ec8"},"source":["restaurant_test_1_predictions_unk_count = classify(restaurant_test_1_data, mixed_sentiment_terms_frequency_train)\n","print(\"Number of Unknown Sentiment Terms:\", restaurant_test_1_predictions_unk_count)\n","restaurant_test_1_data_df = data_list_to_df(restaurant_test_1_data, aspect_terms = \"generated\", aspect_polarity = True)\n","restaurant_test_1_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Unknown Sentiment Terms: 278\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The bread is top notch as well.</td>\n","      <td>[notch]</td>\n","      <td>[[top]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>I have to say they have one of the fastest del...</td>\n","      <td>[times]</td>\n","      <td>[[fastest]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Food is always fresh and hot- ready to eat!</td>\n","      <td>[Food]</td>\n","      <td>[[fresh]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Did I mention that the coffee is OUTSTANDING?</td>\n","      <td>[coffee]</td>\n","      <td>[[OUTSTANDING]]</td>\n","      <td>[neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Certainly not the best sushi in New York, howe...</td>\n","      <td>[sushi, place]</td>\n","      <td>[[best], [clean]]</td>\n","      <td>[positive, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...  Generated Polarities\n","0  1  ...            [positive]\n","1  2  ...            [positive]\n","2  3  ...            [positive]\n","3  4  ...             [neutral]\n","4  5  ...  [positive, positive]\n","\n","[5 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"OV9UZcj6FiKD"},"source":["#### Test-2 Data"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"_9qTnHzOFiKE","outputId":"96a52e46-7916-4d1e-f42e-c513e378aea3"},"source":["restaurant_test_2_data = xml_to_sentences(root_dir + test_2_folder + restaurant_test_2_file, data_type = \"Test-2\")\n","restaurant_test_2_data_df = data_list_to_df(restaurant_test_2_data, aspect_terms = \"none\", aspect_polarity = False)\n","restaurant_test_2_data_df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The bread is top notch as well.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>I have to say they have one of the fastest del...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Food is always fresh and hot- ready to eat!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Did I mention that the coffee is OUTSTANDING?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Certainly not the best sushi in New York, howe...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID                                           Sentence\n","0  1                    The bread is top notch as well.\n","1  2  I have to say they have one of the fastest del...\n","2  3        Food is always fresh and hot- ready to eat!\n","3  4      Did I mention that the coffee is OUTSTANDING?\n","4  5  Certainly not the best sushi in New York, howe..."]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"KeckRG38FiKE","outputId":"96af96ec-bae1-467a-aacd-50edb99fb234"},"source":["restaurant_test_2_predictions_unk_count = classify(restaurant_test_2_data, mixed_sentiment_terms_frequency_train)\n","print(\"Number of Unknown Sentiment Terms:\", restaurant_test_2_predictions_unk_count)\n","restaurant_test_2_data_df = data_list_to_df(restaurant_test_2_data, aspect_terms = \"both\", aspect_polarity = True)\n","restaurant_test_2_data_df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Unknown Sentiment Terms: 239\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Actual Aspect Terms</th>\n","      <th>Actual Sentiment Terms</th>\n","      <th>Actual Polarities</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The bread is top notch as well.</td>\n","      <td>[bread]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[notch]</td>\n","      <td>[[top]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>I have to say they have one of the fastest del...</td>\n","      <td>[delivery times]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[times]</td>\n","      <td>[[fastest]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Food is always fresh and hot- ready to eat!</td>\n","      <td>[Food]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[Food]</td>\n","      <td>[[fresh]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Did I mention that the coffee is OUTSTANDING?</td>\n","      <td>[coffee]</td>\n","      <td>[[]]</td>\n","      <td>[None]</td>\n","      <td>[coffee]</td>\n","      <td>[[OUTSTANDING]]</td>\n","      <td>[neutral]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Certainly not the best sushi in New York, howe...</td>\n","      <td>[sushi, place]</td>\n","      <td>[[], []]</td>\n","      <td>[None, None]</td>\n","      <td>[sushi, place]</td>\n","      <td>[[best], [clean]]</td>\n","      <td>[positive, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...  Generated Polarities\n","0  1  ...            [positive]\n","1  2  ...            [positive]\n","2  3  ...            [positive]\n","3  4  ...             [neutral]\n","4  5  ...  [positive, positive]\n","\n","[5 rows x 8 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"fNxCEkjnecOG","outputId":"ec5f4699-a2a2-4925-cdc9-c49464e36ea6"},"source":["restaurant_test_2_data_ratios = aspect_term_performance(restaurant_test_2_data)\n","pd.DataFrame.from_dict(restaurant_test_2_data_ratios, orient = 'index',columns = [\"Parameters\"])"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Aspect Term Extraction Precision</th>\n","      <td>0.599928</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction Recall</th>\n","      <td>0.643309</td>\n","    </tr>\n","    <tr>\n","      <th>Aspect Term Extraction True Positives</th>\n","      <td>729.512554</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Aspect Terms</th>\n","      <td>1134.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Generated Aspect Terms</th>\n","      <td>1216.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        Parameters\n","Aspect Term Extraction Precision          0.599928\n","Aspect Term Extraction Recall             0.643309\n","Aspect Term Extraction True Positives   729.512554\n","Actual Aspect Terms                    1134.000000\n","Generated Aspect Terms                 1216.000000"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"3kMKiph7FKHi"},"source":["## Save to CSV"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"yO3IO42iNgmC"},"source":["def write_to_csv(data, path):\n","    data_df = data_list_to_df(data, aspect_terms = \"both\", aspect_polarity = True, no_of_rows = len(data))\n","    data_df.to_csv(path_or_buf = path)\n","\n","write_to_csv(laptop_train_data, root_dir + train_folder + \"generated_laptop_train_data.csv\")\n","write_to_csv(laptop_valid_data, root_dir + train_folder + \"generated_laptop_valid_data.csv\")\n","write_to_csv(laptop_test_1_data, root_dir + test_1_folder + \"generated_laptop_test_1_data.csv\")\n","write_to_csv(laptop_test_2_data, root_dir + test_2_folder + \"generated_laptop_test_2_data.csv\")\n","write_to_csv(restaurant_train_data, root_dir + train_folder + \"generated_restaurant_train_data.csv\")\n","write_to_csv(restaurant_valid_data, root_dir + train_folder + \"generated_restaurant_valid_data.csv\")\n","write_to_csv(restaurant_test_1_data, root_dir + test_1_folder + \"generated_restaurant_test_1_data.csv\")\n","write_to_csv(restaurant_test_2_data, root_dir + test_2_folder + \"generated_restaurant_test_2_data.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFBWz70ewcwU"},"source":["# Demo\n"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"1FnNM0E8whFL"},"source":["def test_classify(string,sentiment_terms_frequency_train):\n","    test_data = []\n","    test_data.append(Sentence(1,string,\"Test\"))\n","    test_predictions_unk_count = classify(test_data, mixed_sentiment_terms_frequency_train)\n","    print(f\"Unknown Sentiment Words: {test_predictions_unk_count}\\n\\nAnalysis:\")\n","    test_data_df = data_list_to_df(test_data, aspect_terms = \"generated\", aspect_polarity = True)\n","    return (test_data_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azsePzXrbhFH"},"source":["Positive Polarity"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"s9Gd_5qgbjaM","outputId":"27f4db8e-b915-4972-a6fe-d8f819637525"},"source":["test_classify(\"Also the display is exceptional!\",mixed_sentiment_terms_frequency_train)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Words: 0\n","\n","Analysis:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Also the display is exceptional!</td>\n","      <td>[display]</td>\n","      <td>[[exceptional]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ... Generated Polarities\n","0  1  ...           [positive]\n","\n","[1 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"P2HfM8lWaSyg"},"source":["Negative Polarity"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"OaSOI7MZW8F7","outputId":"babb436a-8632-430c-ca18-38956f246209"},"source":["test_classify(\"The display is beyond horrible.\",mixed_sentiment_terms_frequency_train)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Words: 0\n","\n","Analysis:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The display is beyond horrible.</td>\n","      <td>[display]</td>\n","      <td>[[horrible]]</td>\n","      <td>[negative]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ... Generated Polarities\n","0  1  ...           [negative]\n","\n","[1 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"nXkvvsuUaP4R"},"source":["Multiple Aspect Terms"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"30NZ1wCl_cdi","outputId":"d93b43ba-0335-4d77-c6ec-1aab0727665a"},"source":["test_classify(\"Screen is awesome, battery life is good.\",mixed_sentiment_terms_frequency_train)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Words: 0\n","\n","Analysis:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Screen is awesome, battery life is good.</td>\n","      <td>[Screen, battery life]</td>\n","      <td>[[awesome], [good]]</td>\n","      <td>[positive, positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ...  Generated Polarities\n","0  1  ...  [positive, positive]\n","\n","[1 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"bEcgzt0vaWC8"},"source":["Multiple Sentiment Words"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JVTTBBsyZ2H6","outputId":"a5902e33-9de6-430a-b0a7-460adcdbf280"},"source":["test_classify(\"Its white color is stylish for college students and easy to take to carry and take to classes.\",mixed_sentiment_terms_frequency_train)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Words: 0\n","\n","Analysis:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Its white color is stylish for college student...</td>\n","      <td>[color]</td>\n","      <td>[[white, stylish]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ... Generated Polarities\n","0  1  ...           [positive]\n","\n","[1 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"J6AOomS5aYHe"},"source":["Compound Aspect Words"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"BoOTyO3KW8ZM","outputId":"1691f926-db60-4bd0-c649-901ef31884a7"},"source":["test_classify(\"It's also fairly easy to use the Operating System.\",mixed_sentiment_terms_frequency_train)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Unknown Sentiment Words: 0\n","\n","Analysis:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Sentence</th>\n","      <th>Generated Aspect Terms</th>\n","      <th>Generated Sentiment Terms</th>\n","      <th>Generated Polarities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>It's also fairly easy to use the Operating Sys...</td>\n","      <td>[Operating System]</td>\n","      <td>[[use]]</td>\n","      <td>[positive]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ID  ... Generated Polarities\n","0  1  ...           [positive]\n","\n","[1 rows x 5 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"3JHhV1SFXvoj"},"source":["# Shortcomings and improvements\n","\n","* Some compound aspect terms lack corresponding sentiment words, because despite the abundant rules, a few cases could not be accounted for. For these cases we can use N-gram model to have a prediction, even if it is worse.\n","* Adjectival Modifiers (like \"very good\") are not taken into consideration, as adding those rules fragments the polarity of the base sentiment (\"good\") which causes a drpo in precision.\n","* Negation should be handled in preprocessing and the sentiment converted to the opposite there only. This is not possible without a pretrained model which can find antonyms.\n","\n"]}]}